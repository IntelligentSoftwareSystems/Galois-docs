/**
\page Manual Manual

\section parallel_loop Parallel Loops

\subsection for_each For-Each Loop

 {@link Galois::for_each} is the most commonly used loop construct to express
 parallelism. It provides speculative unordered execution of a set of active
 elements (or work items). A for_each can be invoked with the following parameters:

 - A pair of iterators [begin,end) that mark the set of initial active elements
 - The *operator*, which is a C++ functor containing the loop body code. 
 - The scheduling policy for work items, used by the internal worklist. It is
   specified using the {@link Galois::wl} construct. 
 - Optional argument for specifying the loop name, using the {@link
   Galois::loopname} construct


An example to use for_each in {@link apps/tutorial/SSSPsimple.cpp} can be seen as follows:
@snippet apps/tutorial/SSSPsimple.cpp for_each in SSSPsimple

 - {@link Galois::for_each_ordered}
 
This is for ordered Galois Iterators. 


\subsection operator Operator

The loop body of a {@link Galois::for_each} is specified as a C++ functor. We call
this the *operator* of the loop. The functor takes two arguments:

- The active element (or work item) to process in current iteration. This is picked
  by the runtime using the scheduling policy
- A reference to the runtime context of the loop {@link Galois::UserContext}. This
  reference provides certain services needed by the loop body, e.g. the ability to add 
  new items to the internal worklist (maintained by the runtime), allocate
  iteration local objects, and suspend the parallel loop temporarily, etc.

An example to define an operator in {@link apps/tutorial/SSSPsimple.cpp} can be seen as follows:
@snippet apps/tutorial/SSSPsimple.cpp Operator in SSSPsimple

The operator must be *cautious*. \b TODO: add ref to glossary here

\subsubsection type_traits Type Traits

We can specify several flags as typedefs in the operator to turn on and off certain
features provided by the Galois runtime. Often turning off a feature saves the
runtime cost of providing that feature and results in
optimized execution:

 - \b tt_does_not_need_push

    Indicates the operator does not generate new work and push it on the worklist

 - \b tt_does_not_need_aborts

    Indicates the operator doesn't need support for speculation. All iterations
    will commit successfully

 - \b tt_needs_per_iter_alloc

    Indicates the operator may request the access to a per-iteration allocator
    \b TODO: add ref here

 - \b tt_does_not_need_stats

    Indicates the operator doesn't need to record its execution statistics.

 - \b tt_needs_parallel_break

    Indicates the operator may request the parallel loop to be suspended
    temporarily, at which point another function can be executed serially


\subsection scheduling Scheduling Policies

The scheduling policy for {@link Galois::for_each} can be specified by choosing
one of the types in {@link Galois::WorkList} namespace and providing the type-name
as an argument to {@link Galois::wl} parameter of the for_each. 
The scheduling policies are listed as follows:

 - PriQueue

    implements a std::pri_queue compatible priority queue.

 - FIFO and LIFO
    
    implement std::queue and std::stack like behaviors respectively. 

 - OrderedByIntegerMetric
   
    implements a priority queue based on a supplied function which maps a work item to an integer priority. Lower values are a higher priority. An inner queue may be passed to control how items within the same priority are stored. 

 - ChunkedFIFO and ChunkedLIFO
    
    implement a chunked FIFO or LIFO strategy to reduce contention. Each thread has a chunk of work which it is filling when pushing and a chunk which is being emptied by popping. When a chunk is filled, it is placed on the central FIFO or LIFO. 

 - dChunkedFIFO and dChunkedLIFO
    
    behave like their non-d counterparts, but maintain a FIFO or LIFO per CPU package (usually L3 cache). If a processor's package local FIFO or LIFO is empty, it attempts to steal a chunk from another CPU package.

 - LocalQueues
    create local non-shared worklists which are used for all work generated during concurrent operation and use a global worklist for all initial work. 

An example to define an OrderedByIntegerMetic scheduling in {@link apps/tutorial/SSSPsimple.cpp} can be seen as follows:
@snippet apps/tutorial/SSSPsimple.cpp UpdateRequestIndexer in SSSPsimple

   The UpdateRequestIndexer defines the priority. 

@snippet apps/tutorial/SSSPsimple.cpp OrderedByIntegerMetic in SSSPsimple
   The OBIM is an example to define a priority scheduling. Internally It uses a dChunkedLIFO to store the items with the same priority.

\subsection do_all Do-All Loop

{@link Galois::do_all} is a loop construct for trivially parallel loops that do not
need any speculation, fancy scheduling policies, and do not generate new work items. The
threads iterate in parallel over a range of iterators specified in the invocation
of the do_all. The arguments are as follows:

- A pair of iterators specifying the set of work-items.

- A functor specifying the loop body of the do_all. It takes only one argument,
  which is the current work item. 

- {@link Galois::do_all_steal} can be supplied with argument \b true or \b false to
  turn on work-stealing. This can be useful for loops where iterations have varying
  execution time. 

- Optionally {@link Galois::loopname} can be used to specify a name of loop, which
  is useful for loop statistics

The file {@link apps/tutorial/HelloWorld.cpp} contains some examples of do_all
loops:
@snippet apps/tutorial/HelloWorld.cpp do_all example

\subsection for_each_local Locality Aware Loops: for_each_local and do_all_local

Often a parallel loop iterates over (or consumes) data that was produced by a
previous parallel loop. In such cases, locality can be improved if the threads in
the consuming loop operate over the same elements they produced in the previous
loop. This notion of *ownership* of data is supported in Galois, through 
{@link Galois::for_each_local} and {@link Galois::do_all_local}. 

The for_each_local and do_all_local are similar to their non-local counterparts, except
for the first argument. Instead of passing in a pair of iterators, we pass in a
"locality-aware data structure". A locality aware data structure must support 
\b local_begin and \b local_end (in addition to \b begin and \b end), which point
to the range of data items owned/produced by a thread. 

Example of such data-structure is {@link Galois::Graph::FirstGraph}, used in 
{@link apps/delaunayrefinement/DelaunayRefinement.cpp}:

@snippet apps/delaunayrefinement/DelaunayRefinement.cpp do_all_local example

And similarly, for_each_local, in the same file (iterating over a bag 
{@link Galois::InsertBag} of items produced by the do_all_local above):

@snippet apps/delaunayrefinement/DelaunayRefinement.cpp for_each_local example



\subsection on_each on_each loop

{@link Galois::on_each loop is for performing simple tasks on each thread in the
execution. The task is encoded in a functor passed to on_each loop. The functor
takes two arguments:

- \b tid: the thread-id assigned by runtime, which lies in the range
  [0:num-threads). 
- \b num-threads: the total number of threads used for execution

\b TODO: example of on_each
*/
